Thesis
=======

# introduction
- background on representation learning
- representations from DNNs vs. ideal representations


(maybe change this to significance of representation learning)
# desiderata of representations
- disentangling as goal (Bengio paper on representation)


# representations in vision
- introduction
	- graphics engines
		- description of representations
		- advantages of disentanglement
			- interpretability
			- reusability
	- vision as inverse graphics theory
- related work
	- NIPS paper from this year
		- ping Josh once I've got a list to ensure I've covered it
	- capsule networks
	- Spatial Transformers
- description of problem
	- infer the pose of an object and interpret
	- render novel scenes
- model
	- training procedure
- experiments
- discussion of results
- future work


# representations of computation
- introduction
	- disentangled representation of computation
		- <steal from proposal>
		- catastrophic forgetting
		- science as factorization
		- compact representation of combinatorial spaces
	- continuation learning
		- difficulty of learning under hard decisions
		- continuations make it easy to learn, then make it hard
		- scope of problems affected
			- RL NTM
			- Memory Networks
		- previous approaches
- related work
	- neural programmer-interpreters
	- learning to execute
	- learning simple algorithms from examples
	- neural programmer
- description of toy problem
- model <steal from proposal>
- experiments
- discussion
- future work

# conclusion
- overall significance
- directions for the future
- philosophy of research with learning systems
	- designing with soft constraints instead of hard ones
	- the freedom to improvise and the power of the designer
		- it won't be all convolutional nets forever
		- consider the problem, evaluate its needs, and then write down exactly that model
